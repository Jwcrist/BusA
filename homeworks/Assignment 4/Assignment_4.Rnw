\documentclass{article}
\usepackage[vmargin=1in,hmargin=1in]{geometry}
\usepackage{enumerate}
\begin{document}
\title{Homework 3}
\date{BSAD 8700 - Business Analytics\\ Due: February 2, 2015}
\author{Kris Hanus, Laura Glathar, Arkya Rakshit, Jace Crist, Brandon Dlugosz\\ University of Nebraska at Omaha}
\maketitle

\textbf{ANSWER FOR 10:} \\
<<echo=FALSE, warning=FALSE>>=
# install.packages("ISLR", "MASS")
library(MASS)
library(ISLR)
library(ggplot2)
@


\begin{enumerate}[(a)]
\item
<<>>=

tail(Weekly, 1)
summary(Weekly)
data1<-Weekly[,1:8]
attach(Weekly)
cor(data1)
pairs(data1)
@
There are a few interesting places of correlation. Primarily, with Volume and Year. Other wise, it is observable that each of the Lags are clustered, but it is difficult to observe other relationships.

\item
<<>>=
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Weekly, family = binomial)
summary(glm.fit)
coef(glm.fit)
@

The only predictors which have significance are the intercept and Lag2. Lag2 is between $95\%$ and $99\%$ significant. The Intercept is $99\%$ and $99.9\%$.

\item
<<>>=
contrasts(Direction)
glm.pred=rep("Down", 1089)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:10]
glm.pred[glm.probs>0.5]<-"Up"
table(glm.pred,Direction)
557/(557+430)
430/(557+430)
48/(48+54)
@

The confusion matrix shows that on days when logistic regression predicts an increase in the market, it has a $56.4\%$ accuracy rate. The error rate is $43.6\%$ for predicting Up and is actually Down. The error rate is $47.1\%$ for predicting Down and is actually Up.

\item
<<>>=
glm.fit2=glm(Direction~Lag2,data=Weekly, family = binomial)
summary(glm.fit2)
coef(glm.fit2)
contrasts(Direction)
glm.pred2=rep("Down", 1089)
glm.probs2=predict(glm.fit2,type="response")
glm.probs2[1:10]
glm.pred2[glm.probs2>0.5]<-"Up"
table(glm.pred2,Direction)
579/(579+451)
451/(579+451)
26/(26+33)
@

The confusion matrix shows that on days when logistic regression predicts an increase in the market, it has a $56.2\%$ accuracy rate. The error rate is $43.8\%$ for predicting Up and is actually Down. The error rate is $44.1\%$ for predicting Down and is actually Up.
\end{enumerate}

\textbf{ANSWER FOR 11:} \\

\begin{enumerate}[(a)]

\item
<<>>=
#install.packages("RCurl")
library(RCurl)
dataset<-getURL(
    'https://raw.githubusercontent.com/Jwcrist/BusA/master/homeworks/Assignment%204/Auto.csv',
    ssl.verifypeer=0L, followlocation=1L)
dataset1<-read.csv(text=dataset)
head(dataset1,3)
@
As can be shown above we have created our the requested column.

\item
<<>>=
library(dplyr) 
dataset2<-dataset1 %>%
  select(mpg, cylinders, displacement, as.numeric(horsepower), weight, acceleration, year, origin, mpg01)
dataset2$horsepower <- gsub("?",NA,dataset2$horsepower, fixed = TRUE)
dataset2$horsepower <- as.numeric(dataset2$horsepower)
str(dataset2)
cor(na.omit(dataset2))
pairs(dataset1)
library(ggplot2)
ggplot(dataset1, aes(x=factor(mpg01), y=mpg))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=cylinders))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=displacement))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=weight))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=acceleration))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=year))+geom_boxplot()
@

There is too many layers to observe anything of significance in horsepower. Acceleration and year may have be significantly different from eachother. All the other plots show that there is probable differences between our binary factors.
\item
<<>>=
tail(dataset1)
trainingdata<-dataset1[1:318,]
testdata<-dataset1[79,]
@
A $80\%$ training data set was choosen to be used inorder to prove against our test data.

\item
Do Not Do
\item
Do Not Do
\item
<<>>=
attach(dataset2)
glm.fit3=lm(mpg01~mpg+cylinders+horsepower,data=dataset2, family = binomial)
summary(glm.fit3)
coef(glm.fit3)
glm.pred3=rep("0", 397)
glm.probs3=predict(glm.fit3,type="response")
glm.probs3[1:10]
glm.pred3[glm.probs3>0.5]<-"1"
table(glm.pred3,mpg01)
(158+148)/397
43/(158+43)
48/(148+48)
@

Our model predicted with a $77.1\%$ accuracy. The probability that our model incorrectly predicts below median and is above median is $21.4\%$. The probability that our model incorrectly predicts above the median and is below the median is $24.5\%$. 

\end{enumerate}

\end{document}