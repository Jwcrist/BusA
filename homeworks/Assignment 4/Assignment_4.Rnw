\documentclass{article}
\usepackage[vmargin=1in,hmargin=1in]{geometry}
\usepackage{enumerate}
\begin{document}
\title{Homework 4}
\date{BSAD 8700 - Business Analytics\\ Due: February 9, 2015}
\author{Kris Hanus, Laura Glathar, Arkya Rakshit, Jace Crist, Brandon Dlugosz\\ University of Nebraska at Omaha}
\maketitle

\textbf{ANSWER FOR 10:} \\
<<echo=FALSE, warning=FALSE>>=
# install.packages("ISLR", "MASS")
library(MASS)
library(ISLR)
library(ggplot2)
@


\begin{enumerate}[(a)]
\item
<<>>=

tail(Weekly, 1)
summary(Weekly)
data1<-Weekly[,1:8]
attach(Weekly)
cor(data1)
pairs(data1)
@
There are a few interesting places of correlation. Primarily, with Volume and Year. Other wise, it is observable that each of the Lags are clustered, but it is difficult to observe other relationships.

\item
<<>>=
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Weekly, family = binomial)
summary(glm.fit)
coef(glm.fit)
@

The only predictors which have significance are the intercept and Lag2. Lag2 is between $95\%$ and $99\%$ significant. The Intercept is $99\%$ and $99.9\%$.

\item
<<>>=
contrasts(Direction)
glm.pred=rep("Down", 1089)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:10]
glm.pred[glm.probs>0.5]<-"Up"
table(glm.pred,Direction)
(54+557)/(557+430)
430/(48+430)
48/(48+430)
@

The confusion matrix shows that on days when logistic regression predicts an increase in the market, it has a $61.9\%$ accuracy rate. $90\%$ of the error is predicting Up and is actually Down. $10\%$ for predicting Down and is actually Up.

\item
<<>>=
glm.fit2=glm(Direction~Lag2,data=Weekly, family = binomial)
summary(glm.fit2)
coef(glm.fit2)
contrasts(Direction)
glm.pred2=rep("Down", 1089)
glm.probs2=predict(glm.fit2,type="response")
glm.probs2[1:10]
glm.pred2[glm.probs2>0.5]<-"Up"
table(glm.pred2,Direction)
(33+579)/(579+451)
451/(26+451)
26/(26+451)
@

The confusion matrix shows that on days when logistic regression predicts an increase in the market, it has a $59.4\%$ accuracy rate. $94.6\%$ of the error is predicting Up and is actually Down. $5.5\%$ for predicting Down and is actually Up.
\end{enumerate}

\textbf{ANSWER FOR 11:} \\

\begin{enumerate}[(a)]

\item
<<>>=
#install.packages("RCurl")
library(RCurl)
dataset<-getURL(
    'https://raw.githubusercontent.com/Jwcrist/BusA/master/homeworks/Assignment%204/Auto.csv',
    ssl.verifypeer=0L, followlocation=1L)
dataset1<-read.csv(text=dataset)
head(dataset1,3)
@
As can be shown above we have created our the requested column.

\item
<<warning=FALSE>>=
library(dplyr) 
dataset2<-dataset1 %>%
  select(mpg, cylinders, displacement, as.numeric(horsepower), weight, acceleration, year, origin, mpg01)
dataset2$horsepower <- gsub("?",NA,dataset2$horsepower, fixed = TRUE)
dataset2$horsepower <- as.numeric(dataset2$horsepower)
str(dataset2)
cor(na.omit(dataset2))
pairs(dataset1)
library(ggplot2)
ggplot(dataset1, aes(x=factor(mpg01), y=mpg))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=cylinders))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=displacement))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=weight))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=acceleration))+geom_boxplot()
ggplot(dataset1, aes(x=factor(mpg01), y=year))+geom_boxplot()
@

There is too many layers to observe anything of significance in horsepower. As far as our response variable, acceleration and year can not be shown to be significantly different from either mpg01 class. All the other plots show that there is probable differences between the binary factors.
\item
<<>>=
tail(dataset1)
trainingdata<-dataset1[1:318,]
testdata<-dataset1[319:397,]
dim(testdata)
@
An $80\%$ training data set was choosen.

\item
Do Not Do
\item
Do Not Do
\item

<<warning=FALSE>>=
attach(dataset2)
glm.fit3=lm(mpg01~mpg+cylinders+horsepower,data=dataset2, family = binomial)
summary(glm.fit3)
coef(glm.fit3)
glm.pred3=rep("0", 397)
glm.probs3=predict(glm.fit3,type="response")
glm.probs3[1:10]
glm.pred3[glm.probs3>0.5]<-"1"
table(glm.pred3,mpg01)
(158+148)/397
43/(158+43)
48/(148+48)
@

Our model predicted with a $77.1\%$ accuracy. The probability that our model incorrectly predicts below median and is above median is $21.4\%$. The probability that our model incorrectly predicts above the median and is below the median is $24.5\%$. 

\end{enumerate}

\end{document}